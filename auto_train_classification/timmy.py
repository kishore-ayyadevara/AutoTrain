# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/02_vision.external.timm.ipynb (unless otherwise specified).

__all__ = ['create_timm_body', 'create_timm_model', 'timm_learner', 'DecoderBlock', 'BatchNormZero', 'UnetDecoder',
           'UnetHead', 'TimmUnet', 'split_nested_list', 'timm_unet_learner']

# Cell
from fastai.vision.all import *

# Cell
from timm import create_model
from fastai.vision.learner import _update_first_layer

# Cell
def create_timm_body(arch:str, pretrained=True, cut=None, n_in=3):
    "Creates a body from any model in the `timm` library."
    model = create_model(arch, pretrained=pretrained, num_classes=0, global_pool='')
    _update_first_layer(model, n_in, pretrained)
    if cut is None:
        ll = list(enumerate(model.children()))
        cut = next(i for i,o in reversed(ll) if has_pool_type(o))
    if isinstance(cut, int): return nn.Sequential(*list(model.children())[:cut])
    elif callable(cut): return cut(model)
    else: raise NamedError("cut must be either integer or function")

# Cell
def create_timm_model(arch:str, n_out, cut=None, pretrained=True, n_in=3, init=nn.init.kaiming_normal_, custom_head=None,
                     concat_pool=True, **kwargs):
    "Create custom architecture using `arch`, `n_in` and `n_out` from the `timm` library"
    body = create_timm_body(arch, pretrained, None, n_in)
    if custom_head is None:
        nf = num_features_model(nn.Sequential(*body.children()))
        head = create_head(nf, n_out, concat_pool=concat_pool, **kwargs)
    else: head = custom_head
    model = nn.Sequential(body, head)
    if init is not None: apply_init(model[1], init)
    return model

# Cell
from fastai.vision.learner import _add_norm

# Cell
def timm_learner(dls, arch:str, loss_func=None, pretrained=True, cut=None, splitter=None,
                y_range=None, config=None, n_out=None, normalize=True, **kwargs):
    "Build a convnet style learner from `dls` and `arch` using the `timm` library"
    if config is None: config = {}
    if n_out is None: n_out = get_c(dls)
    assert n_out, "`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`"
    if y_range is None and 'y_range' in config: y_range = config.pop('y_range')
    model = create_timm_model(arch, n_out, default_split, pretrained, y_range=y_range, **config)
    learn = Learner(dls, model, loss_func=loss_func, splitter=default_split, **kwargs)
    if pretrained: learn.freeze()
    return learn

# Cell
class DecoderBlock(Module):
    """
    Decoder Block based off https://gist.github.com/rwightman/f8b24f4e6f5504aba03e999e02460d31
    """
    def __init__(self, up_in_c, s_in_c, scale=2, blur=False,  final_div=True,
                 act_cls=defaults.activation, init=nn.init.kaiming_normal_, norm_type=None, **kwargs):
        self.shuf = PixelShuffle_ICNR(up_in_c, up_in_c//2, scale=scale, blur=blur, act_cls=act_cls, norm_type=norm_type, **kwargs)
        self.bn = BatchNorm(s_in_c)
        self.act = act_cls()
        ni = up_in_c//2 + s_in_c
        nf = ni if final_div else ni//2
        self.nf = nf
        self.conv1 = ConvLayer(ni, nf, act_cls=act_cls, norm_type=norm_type, **kwargs)
        self.conv2 = ConvLayer(nf, nf, act_cls=act_cls, norm_type=norm_type, **kwargs)
        apply_init(nn.Sequential(self.shuf, self.bn, self.conv1, self.conv2), init)

    def forward(self, up_in: torch.Tensor, skip: Optional[torch.Tensor] = None):
        x = self.shuf(up_in)
        if skip is not None:
            ssh = skip.shape[-2:]
            if ssh != x.shape[-2:]:
                x = F.interpolate(x, ssh, mode='nearest')
            x = self.act(torch.cat([x, self.bn(skip)], dim=1))
        return self.conv2(self.conv1(x))

# Cell
@delegates(nn.BatchNorm2d)
def BatchNormZero(nf, ndim=2, **kwargs):
    "BatchNorm layer with `nf` features and `ndim` initialized depending on `norm_type`. Weights initialized to zero."
    return _get_norm('BatchNorm', nf, ndim, zero=True, **kwargs)


def _make_bottleneck(bottleneck, ni, act_cls=defaults.activation, norm_type=None, init=nn.init.kaiming_normal_, **kwargs):
    if bottleneck == 'conv':
        seq = nn.Sequential(BatchNorm(ni), nn.ReLU(),
                            ConvLayer(ni, ni*2, act_cls=act_cls, norm_type=norm_type, **kwargs),
                            ConvLayer(ni*2, ni, act_cls=act_cls, norm_type=norm_type, **kwargs))
    elif bottleneck == 'attention':
        seq = nn.Sequential(BatchNormZero(ni), nn.ReLU(),
                            ConvLayer(ni, ni, act_cls=act_cls, norm_type=norm_type, **kwargs),
                            SimpleSelfAttention(ni, ks=1))
    elif bottleneck == 'double_attention':
        seq = nn.Sequential(BatchNormZero(ni), nn.ReLU(),
                            ConvLayer(ni, ni, act_cls=act_cls, norm_type=norm_type, **kwargs),
                            SimpleSelfAttention(ni, ks=1),
                            ConvLayer(ni, ni, act_cls=act_cls, norm_type=norm_type, **kwargs),
                            SimpleSelfAttention(ni, ks=1))
    else: raise NotImplementedError(f'Bottleneck architecture {bottleneck} not implemented.')
    apply_init(seq, init)
    return seq

# Cell
from typing import List

# Cell
class UnetDecoder(Module):
    """
    Unet Decoder  based off https://gist.github.com/rwightman/f8b24f4e6f5504aba03e999e02460d31
    """
    def __init__(self, encoder, bottleneck=None, blur=False, blur_final=True,
                 norm_type=None, act_cls=defaults.activation, init=nn.init.kaiming_normal_, **kwargs):


        encoder_chs = encoder.feature_info.channels()[::-1]
        encoder_reds = encoder.feature_info.reduction()
        skip_channels = L(encoder_chs[1:])

        self.blocks = nn.ModuleList()
        up_c = encoder_chs[0]
        self.bottleneck = _make_bottleneck(bottleneck, up_c, act_cls=act_cls, norm_type=norm_type, init=init, **kwargs) if isinstance(bottleneck,str) else bottleneck
        for i,skip_c in enumerate(skip_channels):
            not_final = i!=len(skip_channels)-1
            do_blur = blur and (not_final or blur_final)
            scale = encoder_reds.pop()//encoder_reds[-1]
            block = DecoderBlock(up_c, skip_c, scale=scale, blur=do_blur, final_div=not_final, act_cls=act_cls, init=init, norm_type=norm_type, **kwargs)
            up_c = block.nf
            self.blocks.append(block)

        scale = encoder_reds[0]
        self.final_shuf = PixelShuffle_ICNR(up_c, scale=scale, act_cls=act_cls, norm_type=norm_type, **kwargs) if scale!= 1 else None
        self.nf = up_c

    def forward(self, x: List[torch.Tensor]):
        x.reverse()  # torchscript doesn't work with [::-1]
        skips = x[1:]
        x = x[0]
        if self.bottleneck is not None: x = self.bottleneck(x)
        for i, b in enumerate(self.blocks):
            skip = skips[i] if i < len(skips) else None
            x = b(x, skip)
        if self.final_shuf is not None: x = self.final_shuf(x)
        return x

# Cell
class UnetHead(SequentialEx):
    "Head of a Unet Model"
    def __init__(self, up_c, n_out, last_cross=False, n_in=None, bottle=False, norm_type=None, act_cls=defaults.activation, init=nn.init.kaiming_normal_, y_range=None, **kwargs):
        layers = nn.ModuleList([ResizeToOrig()])
        if last_cross:
            if n_in is None: raise AttributeError('You must specify `n_in` if `last_cross=True`.')
            up_c += n_in
            layers.extend([MergeLayer(dense=True), ResBlock(1, up_c, up_c//2 if bottle else up_c, act_cls=act_cls, norm_type=norm_type, **kwargs)])
        layers.append(nn.Conv2d(up_c, n_out, kernel_size=(1, 1)))
        if y_range is not None: layers.append(SigmoidRange(*y_range))
        super().__init__(*layers)
        apply_init(self, init)

# Cell
class TimmUnet(SequentialEx):
    """
    Unet is a fully convolution neural network for image semantic segmentation

    Args:
        - `encoder`: name of classification model (without last dense layers) used as feature
            extractor to build segmentation model.
        - `n_in`: number of input channels.
        - `n_out`: number of output_channels
        - `encoder_kwargs`: kwargs for the encoder
        - `encoder_indices`: indices of layers at which encoder features are extracted.
        - `blur`: use blur inside PixelShuffle_ICNR.
        - `blur_final`: use blur inside the final decoder block.
        - `bottleneck`: one of 'conv' (two conv blocks), 'attention' (conv block followed by SimpleSelfAttention),
            'double_attention' (like 'attention' but twice in series).
        - `last_cross`: concatenate input before final layers.
        - `pretrained`: use pretrained weights in the encoder.
        - `y_range`: attach a scaled sigmoid layer to the end.
        - `bottle`: bottleneck structure in the final ResBlock layer (if last_cross).
    """

    def __init__(self, encoder='resnet50', n_in=3, n_out=1, encoder_kwargs=None, encoder_indices=None,
                 blur=False, blur_final=True,
                 bottleneck=None, last_cross=True, norm_type=None, act_cls=defaults.activation,
                 init=nn.init.kaiming_normal_, pretrained=True, y_range=None, bottle=False, **kwargs):
        encoder_kwargs = encoder_kwargs or {}
        # NOTE some models need different backbone indices specified based on the alignment of features
        # and some models won't have a full enough range of feature strides to work properly.
        self.encoder = create_model(encoder, features_only=True, out_indices=encoder_indices, in_chans=n_in,
                                    pretrained=pretrained, **encoder_kwargs)

        self.decoder = UnetDecoder(self.encoder, bottleneck=bottleneck, blur=blur, blur_final=blur_final,
                                   norm_type=norm_type, act_cls=act_cls, init=init, **kwargs)

        self.head = UnetHead(self.decoder.nf, n_out, last_cross=last_cross, n_in=n_in, bottle=bottle,
                             norm_type=norm_type, act_cls=act_cls, init=init, y_range=y_range, **kwargs)
        super().__init__(nn.Sequential(self.encoder, self.decoder), *self.head)

    @property
    def default_cfg(self): return self.encoder.default_cfg
    @property
    def feature_info(self): return self.encoder.feature_info

# Cell
def _get_params_from_attrs(m, ls): return params(nn.Sequential(*getattrs(m, *ls)))
def _get_params_from_modules(modules): return params(nn.Sequential(*modules))

def split_nested_list(l, idxs, left_in=None, right_in=None):
    left_in,right_in = ifnone(left_in,L()),ifnone(right_in,L())
    idx = int(idxs[0])
    if len(idxs)==1: left,right = l[:idx],l[idx:]
    else: left,right = split_nested_list(l[idx], idxs[1:], l[:idx], l[idx+1:])
    return L(L(*left_in,*left), L(*right,*right_in))

def _timm_splitter(m):
    encoder_module_names = L(m.encoder._modules)
    encoder_split_idxs = m.feature_info.module_name(0).split('.')
    # the first idx is a (unique) name so we convert it to a numerical idx
    encoder_split_idxs[0] = encoder_module_names.index(encoder_split_idxs[0])
    encoder_modules = getattrs(m.encoder,*encoder_module_names)
    encoder_early,encoder_late = split_nested_list(encoder_modules,encoder_split_idxs)
    encoder_early = _get_params_from_modules(encoder_early)
    encoder_late = _get_params_from_modules(encoder_late)
    decoder = _get_params_from_attrs(m.decoder, L(m.decoder._modules))
    head = _get_params_from_attrs(m.head, L(m.head._modules))
    return L(encoder_early, encoder_late, L(*decoder, *head))

# Cell
def _timm_stats(m): return tuple((list(m.default_cfg[stat]) for stat in ('mean','std')))

# Cell
@delegates(TimmUnet.__init__)
def timm_unet_learner(dls, arch, normalize=True, n_in=None, n_out=None, pretrained=True,
                 # learner args
                 loss_func=None, opt_func=Adam, lr=defaults.lr, splitter=None, cbs=None, metrics=None, path=None,
                 model_dir='models', wd=None, wd_bn_bias=False, train_bn=True, moms=(0.95,0.85,0.95),
                 # other model args
                 bottleneck='conv',
                 **kwargs):
    "Build a Unet learner with a timm backbone from `dls` and `arch`"

    n_in = ifnone(n_in, dls.one_batch()[0].shape[1])
    n_out = ifnone(n_out, get_c(dls))
    assert n_out, "`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`"
    model = TimmUnet(arch, n_in=n_in, n_out=n_out, pretrained=pretrained, bottleneck=bottleneck, **kwargs)

    if normalize: _add_norm(dls, {'stats': _timm_stats(model)}, pretrained)
    splitter=ifnone(splitter, _timm_splitter)
    learn = Learner(dls=dls, model=model, loss_func=loss_func, opt_func=opt_func, lr=lr, splitter=splitter, cbs=cbs,
                   metrics=metrics, path=path, model_dir=model_dir, wd=wd, wd_bn_bias=wd_bn_bias, train_bn=train_bn,
                   moms=moms)
    if pretrained: learn.freeze()
    # keep track of args for loggers
    store_attr('arch,normalize,n_out,pretrained', self=learn, **kwargs)
    return learn